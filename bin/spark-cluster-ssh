#!/usr/bin/env python

from dtde import clusterlib, util
import argparse 
import os

try:
    import configparser
except ImportError:
    import ConfigParser as configparser

# Path to config
CONFIG_PATH = os.path.join(os.path.dirname(__file__), '../configuration.cfg') 

if __name__ == '__main__':

    pool_id = None
    jupyter = None
    webui = None
    masterui = None
    username = None
    connect = True

    # parse arguments
    parser = argparse.ArgumentParser(prog='az_spark')

    parser.add_argument('--cluster-id', required=True,
                        help='The unique id of your spark cluster')
    parser.add_argument('--masterui', 
                        help='Local port to port spark\'s master UI to')
    parser.add_argument('--webui', 
                        help='Local port to port spark\'s webui to')
    parser.add_argument('--jupyter', 
                        help='Local port to port jupyter to')
    parser.add_argument('-u', '--username', 
                        help='Username to spark cluster')
    parser.add_argument('--no-connect',
                        action='store_false',
                        default=True,
                        help='Do not create the ssh session. Only print out \
                        the command to run.')

    args = parser.parse_args()
 
    if (args.no_connect is True and args.username is None):
        print('You must specify a username in order to connect automatically.')
        exit()

    if args.cluster_id is not None:
        pool_id = args.cluster_id

    if args.masterui is not None:
        masterui = args.masterui

    if args.webui is not None:
        webui = args.webui

    if args.jupyter is not None:
        jupyter = args.jupyter

    if args.username is not None:
        username = args.username

    if args.no_connect is not None:
        if (args.no_connect is True and username is None):
            connect = False
        elif (args.no_connect is False):
            connect = False

    print('-------------------------------------------')
    print('spark cluster id:    {}'.format(pool_id))
    print('open masterui:       {}'.format(masterui))
    print('open webui:          {}'.format(webui))
    print('open jupyter:        {}'.format(jupyter))
    print('ssh username:        {}'.format(username))
    print('connect:             {}'.format(connect))
    print('-------------------------------------------')

    # Read config file
    global_config = configparser.ConfigParser()
    global_config.read(CONFIG_PATH)

    # Set up batch configuration
    batch_account_key = global_config.get('Batch', 'batchaccountkey')
    batch_account_name = global_config.get('Batch', 'batchaccountname')
    batch_service_url = global_config.get('Batch', 'batchserviceurl')

    # create batch client
    batch_client = util.create_batch_client(
            batch_account_key,
            batch_account_name,
            batch_service_url)

    # get ssh command
    clusterlib.ssh(
        batch_client, 
        pool_id = pool_id,
        masterui = masterui,
        webui = webui,
        jupyter = jupyter,
        username = username,
        connect = connect)
